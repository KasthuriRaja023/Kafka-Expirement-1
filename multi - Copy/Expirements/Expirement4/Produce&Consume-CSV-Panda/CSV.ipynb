{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kafka-pyton-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install confluent_kafka streamz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = ['localhost:29092', 'localhost:29093']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "def create_topic(topic_name, num_partitions, replication_factor):\n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=['localhost:29092', 'localhost:29093'],\n",
    "        client_id='test_client'\n",
    "    )\n",
    "    \n",
    "    topic_list = []\n",
    "    topic_list.append(NewTopic(name=topic_name, num_partitions=num_partitions, replication_factor=replication_factor))\n",
    "    admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
    "\n",
    "    admin_client.close()\n",
    "    print(f\"Topic '{topic_name}' created successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_topic(\"csvdata\", 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_with_pandas(file_path):\n",
    "  \"\"\"Reads a CSV file into a Pandas DataFrame.\n",
    "\n",
    "  Args:\n",
    "      file_path (str): The path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      pandas.DataFrame: The DataFrame containing the CSV data.\n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(file_path)\n",
    "  return df\n",
    "\n",
    "# Example usage\n",
    "file_path = 'C:/Users/DELL/Downloads/multi - Copy/Titanic Dataset.csv'\n",
    "data = read_csv_with_pandas(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def create_producer(bootstrap_servers):\n",
    "   return Producer({'bootstrap.servers': bootstrap_servers})\n",
    "\n",
    "\n",
    "def produce_messages(producer, topic, messages):\n",
    "   for message in messages:\n",
    "       producer.produce(topic, message)\n",
    "       producer.flush()\n",
    "       time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   bootstrap_servers = 'localhost:29092,localhost:29093'\n",
    "   topic = 'testjava'\n",
    "   messages = data\n",
    "  \n",
    "   producer = create_producer(bootstrap_servers)\n",
    "   produce_messages(producer, topic, messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from streamz import Stream\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_consumer_params(bootstrap_servers, group_id):\n",
    "   return {\n",
    "       'bootstrap.servers': bootstrap_servers,\n",
    "       'group.id': group_id,\n",
    "       'auto.offset.reset': 'earliest'\n",
    "   }\n",
    "\n",
    "\n",
    "def consume_and_process(message_batch):\n",
    "   word_counts = Counter()\n",
    "  \n",
    "   for message in message_batch:\n",
    "       words = message.decode('utf-8').split()\n",
    "       for word in words:\n",
    "           word_counts[word] += 1\n",
    "\n",
    "\n",
    "   print(\"Current Word Counts:\", word_counts)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   bootstrap_servers = 'localhost:29092,localhost:29093'\n",
    "   group_id = 'wordcount-group'\n",
    "   topic = 'testjava'  # Ensure topic is a string, not a list\n",
    "  \n",
    "   consumer_params = create_consumer_params(bootstrap_servers, group_id)\n",
    "  \n",
    "   stream = Stream.from_kafka_batched(topic, consumer_params, poll_interval='1s', start=True)\n",
    "   stream.map(consume_and_process).sink(lambda x: None)\n",
    "  \n",
    "   stream.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
