{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kafka-python-ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers = ['localhost:29092', 'localhost:29093']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "def create_topic(topic_name, num_partitions, replication_factor):\n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=['localhost:29092', 'localhost:29093'],\n",
    "        client_id='test_client'\n",
    "    )\n",
    "    \n",
    "    topic_list = []\n",
    "    topic_list.append(NewTopic(name=topic_name, num_partitions=num_partitions, replication_factor=replication_factor))\n",
    "    admin_client.create_topics(new_topics=topic_list, validate_only=False)\n",
    "\n",
    "    admin_client.close()\n",
    "    print(f\"Topic '{topic_name}' created successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_topic(\"csvdata\", 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.admin import KafkaAdminClient, ConfigResource, ConfigResourceType\n",
    "from kafka.errors import KafkaError\n",
    "\n",
    "bootstrap_servers=['localhost:29092', 'localhost:29093']\n",
    "\n",
    "# Listing Topics\n",
    "def list_topics(bootstrap_servers):\n",
    "   try:\n",
    "       admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "       topics = admin_client.list_topics()\n",
    "       admin_client.close()\n",
    "       return topics\n",
    "   except KafkaError as e:\n",
    "       print(f\"Failed to list topics: {e}\")\n",
    "       return []\n",
    "   \n",
    "list_topics(bootstrap_servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stram Data Produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def create_producer(bootstrap_servers):\n",
    "   return Producer({'bootstrap.servers': bootstrap_servers})\n",
    "\n",
    "\n",
    "def produce_messages(producer, topic, messages):\n",
    "   for message in messages:\n",
    "       producer.produce(topic, message)\n",
    "       producer.flush()\n",
    "       time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   bootstrap_servers = 'localhost:29092,localhost:29093'\n",
    "   topic = 'testjava'\n",
    "   messages = [\n",
    "       \"hello world\",\n",
    "       \"hello kafka\",\n",
    "       \"hello kafka streams\",\n",
    "       \"kafka streams with python\",\n",
    "       \"python and kafka\",\n",
    "       \"real-time stream processing\"\n",
    "   ]\n",
    "  \n",
    "   producer = create_producer(bootstrap_servers)\n",
    "   produce_messages(producer, topic, messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consume Streamed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from streamz import Stream\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_consumer_params(bootstrap_servers, group_id):\n",
    "   return {\n",
    "       'bootstrap.servers': bootstrap_servers,\n",
    "       'group.id': group_id,\n",
    "       'auto.offset.reset': 'earliest'\n",
    "   }\n",
    "\n",
    "\n",
    "def consume_and_process(message_batch):\n",
    "   word_counts = Counter()\n",
    "  \n",
    "   for message in message_batch:\n",
    "       words = message.decode('utf-8').split()\n",
    "       for word in words:\n",
    "           word_counts[word] += 1\n",
    "\n",
    "\n",
    "   print(\"Current Word Counts:\", word_counts)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   bootstrap_servers = 'localhost:29092,localhost:29093'\n",
    "   group_id = 'wordcount-group'\n",
    "   topic = 'testjava'  # Ensure topic is a string, not a list\n",
    "  \n",
    "   consumer_params = create_consumer_params(bootstrap_servers, group_id)\n",
    "  \n",
    "   stream = Stream.from_kafka_batched(topic, consumer_params, poll_interval='1s', start=True)\n",
    "   stream.map(consume_and_process).sink(lambda x: None)\n",
    "  \n",
    "   stream.start()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
